{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image\n",
    "\n",
    "# lib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# lib for regex\n",
    "import re\n",
    "\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker\n",
    "\n",
    "# for t testing\n",
    "from scipy import stats\n",
    "\n",
    "# lib for better plotting\n",
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n",
    "\n",
    "# lib for differ calculation\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "config_datasheet_path = r'./data/Book4.xlsx'\n",
    "\n",
    "# columns with visual stimulus data\n",
    "config_visual_stimulus_variable_array = ['TR20_01', 'TI20_01', 'BR20_01', 'BI20_01']\n",
    "\n",
    "# columns with names of the algo\n",
    "config_algo_names = ['TR_FIB', 'TI_FIB', 'BR_FIB', 'BI_FIB']\n",
    "\n",
    "# columns with time data of visual stimulus\n",
    "config_time_variable_array = []\n",
    "\n",
    "# columns with the given answers of the studen\n",
    "config_answer_variable_array = ['TR10_01', 'TI10_01', 'BR10_01', 'BI10_01']\n",
    "\n",
    "# regex pattern for correct answer\n",
    "config_answer_pattern_array = ['2', '2','2','2']\n",
    "\n",
    "# colums of response time\n",
    "config_response_time_variable_array = ['TIME042', 'TIME008', 'TIME059', 'TIME023']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for REYEker data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for loading rEYEker settings\n",
    "config_reyeker_settings_path = \"data/example.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for saving images </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for loading the images\n",
    "config_image_path_array = ['images/TR/TR_Fibonacci.png',\n",
    "               'images/TI/TI_Fibonacci.png',\n",
    "               'images/BR/BR_Fibonacci.png',\n",
    "               'images/BI/BI_Fibonacci.png']\n",
    "\n",
    "# where to save to heatmaps and sequence diagrams\n",
    "config_folder_prefix_array = [\n",
    "    'TR/',\n",
    "    'TI/',\n",
    "    'BR/',\n",
    "    'BI/']\n",
    "\n",
    "# used for saving the heatmaps and sequence diagrams\n",
    "config_image_prefix_array = [\n",
    "    'TR_Fibonacci_',\n",
    "    'TI_Fibonacci_',\n",
    "    'BR_Fibonacci_',\n",
    "    'BI_Fibonacci_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for Code Flow data import</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel data in data/code_flow\n",
    "config_code_flow_datasheet_array = ['TR_Fibonacci.xlsx',\n",
    "                  'TI_Fibonacci.xlsx',\n",
    "                  'BR_Fibonacci.xlsx',\n",
    "                  'BI_Fibonacci.xlsx']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for alpha value for t-test </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence needed for t test\n",
    "config_alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the columns and create dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns_array = []\n",
    "\n",
    "# create all dataframe headers\n",
    "for i in range(len(config_visual_stimulus_variable_array)):\n",
    "    tmp_list = []\n",
    "    tmp_list.append(config_visual_stimulus_variable_array[i])\n",
    "    \n",
    "    if len(config_time_variable_array) != 0:\n",
    "        tmp_list.append(config_time_variable_array[i])\n",
    "\n",
    "    tmp_list.append(config_answer_variable_array[i])\n",
    "    tmp_list.append(config_response_time_variable_array[i])\n",
    "    needed_columns_array.append(tmp_list)\n",
    "\n",
    "df_array = []\n",
    "raw = pd.read_excel(config_datasheet_path)\n",
    "\n",
    "# read all dataframes\n",
    "for data_set in needed_columns_array:\n",
    "    dataframe = pd.DataFrame(raw, columns = data_set)\n",
    "    dataframe = dataframe.iloc[1:]\n",
    "    dataframe = dataframe.dropna()\n",
    "    df_array.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Splitting Dataframes in right and wrong answers.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_array_right = []\n",
    "df_array_wrong = []\n",
    "\n",
    "# iter over every dataframe\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    right_answer_pattern = config_answer_pattern_array[idx]\n",
    "    regex = re.compile(right_answer_pattern)\n",
    "    answer_field = config_answer_variable_array[idx]\n",
    "    \n",
    "    dataframe_right = pd.DataFrame(columns = needed_columns_array[idx])\n",
    "    dataframe_wrong = pd.DataFrame(columns = needed_columns_array[idx])\n",
    "    \n",
    "    # iter over every row and check if the result is rightr\n",
    "    for _idx, row  in dataframe.iterrows():\n",
    "        result = regex.match(str(row[answer_field]))\n",
    "        if result is not None:\n",
    "            dataframe_right = dataframe_right.append(row)\n",
    "        else:\n",
    "            dataframe_wrong = dataframe_wrong.append(row)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_array_right.append(dataframe_right)\n",
    "    df_array_wrong.append(dataframe_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Remove Outliers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_array = []\n",
    "tmp_df_array_wrong = []\n",
    "\n",
    "#iterate over all dataframes and remove outliers\n",
    "for idx, dataframe in enumerate(df_array_right):\n",
    "\n",
    "    data = dataframe[config_response_time_variable_array[idx]]\n",
    "    cleared_dataframe = dataframe[data.between(data.quantile(.15), data.quantile(0.85))]\n",
    "    tmp_df_array.append(cleared_dataframe)\n",
    "    \n",
    "#iterate over all dataframes and remove outliers\n",
    "for idx, dataframe in enumerate(df_array_wrong):\n",
    "    data = dataframe[config_response_time_variable_array[idx]]\n",
    "    cleared_dataframe = dataframe[data.between(data.quantile(.15), data.quantile(0.85))]\n",
    "    tmp_df_array_wrong.append(cleared_dataframe)\n",
    "    \n",
    "df_array = tmp_df_array\n",
    "df_array_wong = tmp_df_array_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import REYeker Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_data, _times, click_setting) = rEYEker.load_data_from_json(config_reyeker_settings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "\n",
    "# read in every image\n",
    "for image_path in config_image_path_array:\n",
    "    img = rEYEker.load_image(image_path)\n",
    "    image_array.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    visual_stimulus_array = []\n",
    "    visual_stimulus_row = config_visual_stimulus_variable_array[idx]\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, item in dataframe.iterrows():\n",
    "        data_str = item[visual_stimulus_row]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "        \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            coordinate = coordinate_str.split(\"-\")\n",
    "            coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "            coordinates.append(coordinate)\n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix.append(visual_stimulus_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_data_matrix = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    if len(config_time_variable_array) <= idx:\n",
    "        break\n",
    "    time_measurements = []\n",
    "    time_measurement_row = config_time_variable_array[idx]\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, item in dataframe.iterrows():\n",
    "        data_str = item[time_measurement_row]\n",
    "        data_str = data_str.strip()\n",
    "        timestamps = data_str.split(\" \")\n",
    "        timestamps = [int(timestamp) for timestamp in timestamps]\n",
    "        time_measurement_row.append(timestamps)\n",
    "        \n",
    "    timestamps_data_matrix.append(visual_stimulus_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param image_array:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    prefix = folder + image_name\n",
    "    \n",
    "    #TODO create folders if there are none present\n",
    "    for idx, data in enumerate(image_array):\n",
    "        data = data*255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + '.png')\n",
    "        \n",
    "def compare_for_h0(arr_1, arr_2, alpha):\n",
    "    t, p = stats.ttest_ind(arr_1, arr_2)\n",
    "    if p > alpha:\n",
    "        return True, t, p\n",
    "    else:\n",
    "        return False, t, p\n",
    "    \n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_matrix = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    time_stamp_array = None\n",
    "    if len(timestamps_data_matrix) > dataset_idx:\n",
    "        time_stamp_array = timestamps_data_matrix[dataset_idx]\n",
    "    \n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        times = None\n",
    "        if time_stamp_array is not None and len(time_stamp_array) > visual_idx:\n",
    "            times = time_stamp_array[visual_idx]\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array[dataset_idx], stimulus_measurement,click_setting, times, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "        \n",
    "    heatmaps_matrix.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, heatmap_array in enumerate(heatmaps_matrix):\n",
    "    save_images(heatmap_array, \"./results/heatmaps/heatmaps/\" +  config_folder_prefix_array[idx], config_image_prefix_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_heatmap_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    image = image_array[idx]\n",
    "    visual_measurements = visual_stimulus_data_matrix[idx]\n",
    "    time_measurements = None\n",
    "    if len(timestamps_data_matrix) > idx:\n",
    "        time_measurements = timestamps_data_matrix[idx]\n",
    "    im = rEYEker.draw_average_shape_heat_map_rel(image, visual_measurements, click_setting, 1.0, .0, time_measurements, should_copy=True)\n",
    "    average_heatmap_array.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, heatmap in enumerate(average_heatmap_array):\n",
    "    save_images([heatmap], \"./results/heatmaps/average_heatmap/\", config_image_prefix_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_diagrams_matrix = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    #if time will be needed someday\n",
    "    #time_stamp_array = None\n",
    "    #if len(timestamps_data_matrix) > dataset_idx:\n",
    "    #    time_stamp_array = timestamps_data_matrix[dataset_idx]\n",
    "    \n",
    "    sequence_diagram_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        #if time will be needed someday\n",
    "        #times = None\n",
    "        #if time_stamp_array is not None and len(time_stamp_array) > visual_idx:\n",
    "        #    times = time_stamp_array[visual_idx]\n",
    "        try:\n",
    "            im = rEYEker.draw_vertical_line_diagram(image_array[dataset_idx], stimulus_measurement, should_copy=True)\n",
    "            sequence_diagram_array.append(im)\n",
    "        except:\n",
    "            #TODO\n",
    "            print(\"W.I.P.:\", end='')\n",
    "            print(\"to many clicks for dataset \" + str(dataset_idx) + \" datset \" + str(visual_idx))\n",
    "    sequence_diagrams_matrix.append(sequence_diagram_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sequence_diagram_array in enumerate(sequence_diagrams_matrix):\n",
    "    save_images(sequence_diagram_array, \"./results/sequence_diagrams/\"  +  config_folder_prefix_array[idx], config_image_prefix_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Generate Code Flow diagramm</h2>\n",
    "\n",
    "<h4> User rEYEke_COdeFlow.ipynb to create the corresponding excel sheets </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>7. Analyse average of Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.1 Helper Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_displots(folder, indexing_array, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    indexing_array: how to index into the dataframe\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for idx, dataframe in enumerate(df_array):\n",
    "        values = dataframe[indexing_array[idx]].values.astype(float)\n",
    "        sns_plot = sns.displot(data=values, kde=True)\n",
    "        sns_plot.savefig(folder + config_image_prefix_array[idx] + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "def save_combined_displot(folder, x_axis, dataframe):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    x_axis:         value to use for x_axis\n",
    "    dataframe:      dataframe with \"Algorithm\" field\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.displot(data=dataframe, x=x_axis, hue=\"Algorithm\", kind=\"kde\")\n",
    "    sns_plot.savefig(folder + \"Combined_Displot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_barplot(folder, y_axis, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.barplot(y=y_axis, x='Algorithm', data=df_array, hue='Algorithm', estimator=np.median)\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Barplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxplot(folder, y_axis, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.boxplot(y=y_axis, x='Algorithm', data=df_array, hue='Algorithm')\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Boxplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_violinplot(folder, y_axis, df_array):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    df_array:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.violinplot(y=y_axis, x='Algorithm', data=df_array, hue='Algorithm')\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Violinplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_implots(folder, x_df, x_axis, y_df, y_axis):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tmp_list = []\n",
    "    for idx in range(len(x_df)):\n",
    "        x_val = x_df[x_axis][idx]\n",
    "        y_val = y_df[y_axis][idx]\n",
    "        algorithm = x_df['Algorithm'][idx]\n",
    "        tmp_list.append([x_val, y_val, algorithm])\n",
    "        \n",
    "    df_tmp = pd.DataFrame(tmp_list, columns=[x_axis, y_axis, 'Algorithm'])\n",
    "    for idx in range(len(config_algo_names)):\n",
    "        tmp_df = df_tmp[df_tmp[\"Algorithm\"] == config_algo_names[idx]]\n",
    "        sns_plot = sns.lmplot(data=tmp_df, x=x_axis, y=y_axis)\n",
    "        sns_plot.set(ylim=(0, None))\n",
    "        sns_plot.savefig(folder + config_algo_names[idx] + str(idx) + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_combined_implot(folder, x_df, x_axis, y_df, y_axis):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tmp_list = []\n",
    "    for idx in range(len(x_df)):\n",
    "        x_val = x_df[x_axis][idx]\n",
    "        y_val = y_df[y_axis][idx]\n",
    "        algorithm = x_df['Algorithm'][idx]\n",
    "        tmp_list.append([x_val, y_val, algorithm])\n",
    "        \n",
    "    df_tmp = pd.DataFrame(tmp_list, columns=[x_axis, y_axis, 'Algorithm'])\n",
    "    sns_plot = sns.lmplot(data=df_tmp, x=x_axis, y=y_axis, hue=\"Algorithm\")\n",
    "    sns_plot.set(ylim=(0, None))\n",
    "    sns_plot.savefig(folder + \"Combined_Implot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.2 Response Time</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new Dataframe which holds all the response time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Response Time', 'Algorithm']\n",
    "data = []\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data.append([row[config_response_time_variable_array[idx]], config_algo_names[idx]])\n",
    "algo_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Save Displots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_displots(\"./results/responseTime/displots/\", config_response_time_variable_array, df_array)\n",
    "\n",
    "save_combined_displot(\"./results/responseTime/displots/\", \"Response Time\", algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_barplot(\"./results/responseTime/barplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boxplot(\"./results/responseTime/boxplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_violinplot(\"./results/responseTime/violinplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.3. Code Flow vs Visual Stimulus</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load daraframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "config_array = []\n",
    "code_flow_array = []\n",
    "\n",
    "for value in config_code_flow_datasheet_array:\n",
    "    sheet_config = pd.read_excel('./data/code_flow/' + value, sheet_name=\"config\")\n",
    "    sheet_config = sheet_config.astype('int32')\n",
    "    \n",
    "    sheet_code_flow = pd.read_excel('./data/code_flow/' + value, sheet_name=\"values\")\n",
    "    sheet_code_flow = sheet_code_flow.astype('int32')\n",
    "    \n",
    "    config_array.append(sheet_config)\n",
    "    code_flow_array.append(sheet_code_flow)\n",
    "\n",
    "# transform stimulus data into code lines\n",
    "visual_stimulus_code_flow_matrix = []\n",
    "\n",
    "for idx1, visual_stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    converted_to_lines_array = []\n",
    "    \n",
    "    for dataset in visual_stimulus_dataset:\n",
    "        converted_to_lines = []\n",
    "        \n",
    "        for (x, y) in dataset:\n",
    "            num = -1\n",
    "            \n",
    "            for idx2, tup in config_array[idx1].iterrows():\n",
    "                if is_in(y, tup):\n",
    "                    num = idx2\n",
    "            \n",
    "            converted_to_lines.append(num)\n",
    "            \n",
    "        converted_to_lines_array.append(converted_to_lines)\n",
    "        \n",
    "    visual_stimulus_code_flow_matrix.append(converted_to_lines_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sequence for visual stimulus flow\n",
    "        \n",
    "visual_stimulus_flow_matrix = []\n",
    "\n",
    "for idx, visual_stimulus_code_flow_datasets in enumerate(visual_stimulus_code_flow_matrix):\n",
    "    sequence_array = []\n",
    "    multiplier_offset = 10**get_0_offset(len(config_array[idx]))\n",
    "    \n",
    "    for visual_stimulus_code_flow_dataset in visual_stimulus_code_flow_datasets:\n",
    "        sequence = []\n",
    "        \n",
    "        for start in range(len(visual_stimulus_code_flow_dataset)-1):\n",
    "            pre = visual_stimulus_code_flow_dataset[start]\n",
    "            post = visual_stimulus_code_flow_dataset[start+1]\n",
    "            #potential skip if pre and post is equal, may be useful\n",
    "            num = pre * multiplier_offset + post\n",
    "            sequence.append(num)\n",
    "            \n",
    "        sequence_array.append(sequence)\n",
    "        \n",
    "    visual_stimulus_flow_matrix.append(sequence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sequence for code flow\n",
    "code_flow_sequence_array = []\n",
    "\n",
    "for code_flow_dataset in code_flow_array:\n",
    "    sequence = []\n",
    "    multiplier_offset = 10**get_0_offset(len(code_flow_dataset))\n",
    "    \n",
    "    for start in range(len(code_flow_dataset)-1):\n",
    "        pre = code_flow_dataset['code flow'][start]\n",
    "        post = code_flow_dataset['code flow'][start+1]\n",
    "        #potential skip if pre and post is equal, may be useful\n",
    "        num = pre * multiplier_offset + post\n",
    "        sequence.append(num)\n",
    "        \n",
    "    code_flow_sequence_array.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes\n",
    "similarity_matrix = []\n",
    "\n",
    "for idx, code_flow_sequence in enumerate(code_flow_sequence_array):\n",
    "    sim_data = []\n",
    "    for visual_stimulus_sequence in visual_stimulus_flow_matrix[idx]:\n",
    "        sim_data.append(difflib.SequenceMatcher(None, code_flow_sequence, visual_stimulus_sequence).ratio())\n",
    "        \n",
    "    similarity_matrix.append(sim_data)\n",
    "    \n",
    "cols = ['Similarity', 'Algorithm']\n",
    "data = []\n",
    "for idx in range(len(similarity_matrix)):\n",
    "    for score in similarity_matrix[idx]:\n",
    "        data.append([score, config_algo_names[idx]])\n",
    "\n",
    "df_similarity = pd.DataFrame(data, columns=cols)\n",
    "df_similarity_array = []\n",
    "for idx in range(len(code_flow_array)):\n",
    "    df = pd.DataFrame(df_similarity.loc[df_similarity['Algorithm'] == config_algo_names[idx]] ,columns=cols)\n",
    "    df = df.drop('Algorithm', axis=1)\n",
    "    df_similarity_array.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_displots(\"./results/codeFlowSimilarity/displots/\", [\"Similarity\"]*len(similarity_matrix), df_similarity_array)\n",
    "\n",
    "save_combined_displot(\"./results/codeFlowSimilarity/displots/\", \"Similarity\", df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_barplot(\"./results/codeFlowSimilarity/barplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boxplot(\"./results/codeFlowSimilarity/boxplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_violinplot(\"./results/codeFlowSimilarity/violinplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.4. Regression Code Flow and Response time</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_implots(\"./results/codeFlowSimilarity/implots/\", df_similarity, \"Similarity\", algo_df, \"Response Time\")\n",
    "save_combined_implot(\"./results/codeFlowSimilarity/implots/\", df_similarity, \"Similarity\", algo_df, \"Response Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.5. Statistical Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Excel sheet with data containing speedup and significance corresponding to response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statical_data(df_array, indexing_array, folder, name):\n",
    "    def highlight_signficant(s):\n",
    "        if s.name != '#':\n",
    "            is_sig = df_significance[s.name]\n",
    "            return ['background-color: green' if v else '' for v in is_sig]\n",
    "        else:\n",
    "            return ['' for v in s] \n",
    "    \n",
    "    mean_array = []\n",
    "    is_significant = []\n",
    "    t_value_response_time = []\n",
    "    p_value_response_time = []\n",
    "    ratio = []\n",
    "\n",
    "    for idx1, df1 in enumerate(df_array):\n",
    "        different_tmp = [config_algo_names[idx1]]\n",
    "        t_tmp = [config_algo_names[idx1]]\n",
    "        p_tmp = [config_algo_names[idx1]]\n",
    "        ratio_tmp = [config_algo_names[idx1]]\n",
    "    \n",
    "        for idx2, df2 in enumerate(df_array):\n",
    "            (different, t, p) = compare_for_h0(df1[indexing_array[idx1]].values, df2[indexing_array[idx2]],  config_alpha)\n",
    "            different_tmp.append(not different)\n",
    "            t_tmp.append(t)\n",
    "            p_tmp.append(p)\n",
    "            ratio_tmp.append(df1[indexing_array[idx1]].mean() / df2[indexing_array[idx2]].mean())\n",
    "        \n",
    "        is_significant.append(different_tmp)\n",
    "        t_value_response_time.append(t_tmp)\n",
    "        p_value_response_time.append(p_tmp)\n",
    "        ratio.append(ratio_tmp)\n",
    "        mean_array.append(df1[indexing_array[idx1]].mean())\n",
    "    \n",
    "    df_significance = pd.DataFrame(is_significant, columns=['#'] + config_algo_names)\n",
    "\n",
    "    df_t = pd.DataFrame(t_value_response_time, columns=['#'] + config_algo_names)\n",
    "    df_p = pd.DataFrame(p_value_response_time, columns=['#'] + config_algo_names)\n",
    "    df_ratio = pd.DataFrame(ratio, columns=['#'] + config_algo_names)\n",
    "    df_ratio = df_ratio.style.apply(highlight_signficant)\n",
    "    df_mean = pd.DataFrame([mean_array], columns=config_algo_names)\n",
    "\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    writer = pd.ExcelWriter(folder + name + '.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    df_ratio.to_excel(writer, sheet_name='ratio col row', index=False)\n",
    "    df_mean.to_excel(writer, sheet_name='mean value', index=False)\n",
    "    df_significance.to_excel(writer, sheet_name='statistical difference', index=False)\n",
    "    df_p.to_excel(writer, sheet_name='p values', index=False)\n",
    "    df_t.to_excel(writer, sheet_name='t values', index=False)\n",
    "\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_visual = []\n",
    "for dataset_row in visual_stimulus_data_matrix:\n",
    "    tmp_len = []\n",
    "    for dataset in dataset_row:\n",
    "        tmp_len.append(len(dataset))\n",
    "    len_of_visual.append(tmp_len)\n",
    "    \n",
    "len_df_array = []\n",
    "for len_array in len_of_visual:\n",
    "    df = pd.DataFrame(len_array, columns=['len'])\n",
    "    len_df_array.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Excel sheet with data containing speedup and significance corresponding to len of measured visual stimulus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statical_data(df_array, config_response_time_variable_array, './results/excel/', 'TotalResponseTime')\n",
    "create_statical_data(len_df_array, ['len']*len(len_df_array), './results/excel/', 'NumberOfMeasurements')\n",
    "create_statical_data(df_similarity_array, ['Similarity']*len(df_similarity_array), './results/excel/', 'SimilarityToCodeFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>8. Areas of Interest </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to analyze areas of interests?\n",
    "\n",
    "1. find max heat values or values above a treshhold\n",
    "\n",
    "1.1. split to large areas by a certain treshhold\n",
    "\n",
    "1.2. maybe create a bounding box of them and analyze them by prio for better computation time\n",
    "\n",
    "1.2.1. fix aois to lines, mybe to columns if the works seems useful for an algorithm\n",
    "\n",
    "2. analyse how to jump between different regions of interests\n",
    "\n",
    "2.1. categorize just hot areas as aois\n",
    "\n",
    "2.2. categorize everything as aois\n",
    "\n",
    "2.3. list how the code flow jumps between theese regions\n",
    "\n",
    "3. analyse all the data for a mean and statical signifance\n",
    "\n",
    "3.1. maybe implement gernerialized string mean algorithm for medium jumps\n",
    "\n",
    "3.2. maybe use the same as in the code flow [#todo also implement genrerilized string mean for code flow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
