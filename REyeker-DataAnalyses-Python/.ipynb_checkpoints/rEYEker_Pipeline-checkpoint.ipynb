{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image\n",
    "\n",
    "# lib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# lib for regex\n",
    "import re\n",
    "\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker\n",
    "\n",
    "# for t testing\n",
    "from scipy import stats\n",
    "\n",
    "# lib for better plotting\n",
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n",
    "\n",
    "# lib for differ calculation\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "path_to_data = r'./data/Book4.xlsx'\n",
    "\n",
    "# columns with visual stimulus data\n",
    "visual_stimulus_data = ['TR20_01', 'TI20_01', 'BR20_01', 'BI20_01']\n",
    "\n",
    "# columns with names of the algo\n",
    "algo_names = ['TR_FIB', 'TI_FIB', 'BR_FIB', 'BI_FIB']\n",
    "\n",
    "# columns with time data of visual stimulus\n",
    "time_data = []\n",
    "\n",
    "# columns with the given answers of the studen\n",
    "answer_fields = ['TR10_01', 'TI10_01', 'BR10_01', 'BI10_01']\n",
    "\n",
    "# regex pattern for correct answer\n",
    "right_answer_patterns = ['2', '2','2','2']\n",
    "\n",
    "# colums of response time\n",
    "response_time_data = ['TIME042', 'TIME008', 'TIME059', 'TIME023']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for REYEker data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for loading rEYEker settings\n",
    "settings_file = \"data/example.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for saving images </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for loading the images\n",
    "image_paths = ['images/TR/TR_Fibonacci.png',\n",
    "               'images/TI/TI_Fibonacci.png',\n",
    "               'images/BR/BR_Fibonacci.png',\n",
    "               'images/BI/BI_Fibonacci.png']\n",
    "\n",
    "# where to save to heatmaps and sequence diagrams\n",
    "folder_prefix = [\n",
    "    'TR/',\n",
    "    'TI/',\n",
    "    'BR/',\n",
    "    'BI/']\n",
    "\n",
    "# used for saving the heatmaps and sequence diagrams\n",
    "image_prefix = [\n",
    "    'TR_Fibonacci_',\n",
    "    'TI_Fibonacci_',\n",
    "    'BR_Fibonacci_',\n",
    "    'BI_Fibonacci_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for Code Flow data import</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel data in data/code_flow\n",
    "code_flow_data = ['TR_Fibonacci.xlsx',\n",
    "                  'TI_Fibonacci.xlsx',\n",
    "                  'BR_Fibonacci.xlsx',\n",
    "                  'BI_Fibonacci.xlsx']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for alpha value for t-test </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence needed for t test\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the columns and create dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_colums = []\n",
    "\n",
    "# create all dataframe headers\n",
    "for i in range(len(visual_stimulus_data)):\n",
    "    tmp_list = []\n",
    "    tmp_list.append(visual_stimulus_data[i])\n",
    "    \n",
    "    if len(time_data) != 0:\n",
    "        tmp_list.append(time_data[i])\n",
    "    tmp_list.append(answer_fields[i])\n",
    "    tmp_list.append(response_time_data[i])\n",
    "    total_colums.append(tmp_list)\n",
    "\n",
    "dataframes = []\n",
    "raw = pd.read_excel(path_to_data)\n",
    "\n",
    "# read all dataframes\n",
    "for data_set in total_colums:\n",
    "    dataframe = pd.DataFrame(raw, columns = data_set)\n",
    "    dataframe = dataframe.iloc[1:]\n",
    "    dataframe = dataframe.dropna()\n",
    "    dataframes.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Splitting Dataframes in right and wrong answers.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_right = []\n",
    "dataframes_wrong = []\n",
    "\n",
    "# iter over every dataframe\n",
    "for idx, dataframe in enumerate(dataframes):\n",
    "    right_answer_pattern = right_answer_patterns[i]\n",
    "    regex = re.compile(right_answer_pattern)\n",
    "    answer_field = answer_fields[idx]\n",
    "    \n",
    "    dataframe_right = pd.DataFrame(columns = total_colums[idx])\n",
    "    dataframe_wrong = pd.DataFrame(columns = total_colums[idx])\n",
    "    \n",
    "    # iter over every row and check if the result is rightr\n",
    "    for _index, row  in dataframe.iterrows():\n",
    "        result = regex.match(str(row[answer_field]))\n",
    "        if result is not None:\n",
    "            dataframe_right = dataframe_right.append(row)\n",
    "        else:\n",
    "            dataframe_wrong = dataframe_wrong.append(row)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataframes_right.append(dataframe_right)\n",
    "    dataframes_wrong.append(dataframe_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Remove Outliers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataframes = []\n",
    "tmp_dataframes_wrong = []\n",
    "\n",
    "#iterate over all dataframes and remove outliers\n",
    "for idx, dataframe in enumerate(dataframes_right):\n",
    "\n",
    "    data = dataframe[response_time_data[idx]]\n",
    "    cleared_dataframe = dataframe[data.between(data.quantile(.15), data.quantile(0.85))]\n",
    "    tmp_dataframes.append(cleared_dataframe)\n",
    "    \n",
    "#iterate over all dataframes and remove outliers\n",
    "for idx, dataframe in enumerate(dataframes_wrong):\n",
    "    data = dataframe[response_time_data[idx]]\n",
    "    cleared_dataframe = dataframe[data.between(data.quantile(.15), data.quantile(0.85))]\n",
    "    tmp_dataframes_wrong.append(cleared_dataframe)    \n",
    "    \n",
    "dataframes = tmp_dataframes\n",
    "dataframes_wong = tmp_dataframes_wrong "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import REYeker Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_data, _times, click_setting) = rEYEker.load_data_from_json(\"data/example.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "# read in every image\n",
    "for image_path in image_paths:\n",
    "    img = rEYEker.load_image(image_path)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_array = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for idx, dataframe in enumerate(dataframes):\n",
    "    visual_stimulus_measurements = []\n",
    "    visual_stimulus_row = visual_stimulus_data[idx]\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, item in dataframe.iterrows():\n",
    "        data_str = item[visual_stimulus_row]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "        \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            coordinate = coordinate_str.split(\"-\")\n",
    "            coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "            coordinates.append(coordinate)\n",
    "            \n",
    "        visual_stimulus_measurements.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_array.append(visual_stimulus_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_data_array = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for idx, dataframe in enumerate(dataframes):\n",
    "    if len(time_data) <= idx:\n",
    "        break\n",
    "    time_measurements = []\n",
    "    time_measurement_row = time_data[idx]\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, item in dataframe.iterrows():\n",
    "        data_str = item[time_measurement_row]\n",
    "        data_str = data_str.strip()\n",
    "        timestamps = data_str.split(\" \")\n",
    "        timestamps = [int(timestamp) for timestamp in timestamps]\n",
    "        time_measurement_row.append(timestamps)\n",
    "        \n",
    "    timestamps_data_array.append(visual_stimulus_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(ims, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param ims:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    prefix = folder + image_name\n",
    "    \n",
    "    #TODO create folders if there are none present\n",
    "    for idx, data in enumerate(ims):\n",
    "        data = data*255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + '.png')\n",
    "        \n",
    "def compare_for_h0(arr_1, arr_2, alpha):\n",
    "    t, p = stats.ttest_ind(arr_1, arr_2)\n",
    "    if p > alpha:\n",
    "        return (True, t, p)\n",
    "    else:\n",
    "        return (False, t, p)\n",
    "    \n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_datasets_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_array):\n",
    "    time_stamp_array = None\n",
    "    if len(timestamps_data_array) > dataset_idx:\n",
    "        time_stamp_array = timestamps_data_array[dataset_idx]\n",
    "    \n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        times = None\n",
    "        if time_stamp_array is not None and len(time_stamp_array) > visual_idx:\n",
    "            times = time_stamp_array[visual_idx]\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(images[dataset_idx], stimulus_measurement,click_setting, times, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "        \n",
    "    heatmaps_datasets_array.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, heatmap_array in enumerate(heatmaps_datasets_array):\n",
    "    save_images(heatmap_array, \"./results/heatmaps/heatmaps/\" +  folder_prefix[idx], image_prefix[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_heatmaps = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_array):\n",
    "    image = images[idx]\n",
    "    visual_measurements = visual_stimulus_data_array[idx]\n",
    "    time_measurements = None\n",
    "    if len(timestamps_data_array) > idx:\n",
    "        time_measurements = timestamps_data_array[idx]\n",
    "    im = rEYEker.draw_average_shape_heat_map_rel(image, visual_measurements, click_setting, 1.0, .0, time_measurements, should_copy=True)\n",
    "    average_heatmaps.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, heatmap in enumerate(average_heatmaps):\n",
    "    save_images([heatmap], \"./results/heatmaps/average_heatmap/\", image_prefix[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_diagrams_datasets_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_array):\n",
    "    #if time will be needed someday\n",
    "    #time_stamp_array = None\n",
    "    #if len(timestamps_data_array) > dataset_idx:\n",
    "    #    time_stamp_array = timestamps_data_array[dataset_idx]\n",
    "    \n",
    "    sequence_diagram_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        #if time will be needed someday\n",
    "        #times = None\n",
    "        #if time_stamp_array is not None and len(time_stamp_array) > visual_idx:\n",
    "        #    times = time_stamp_array[visual_idx]\n",
    "        try:\n",
    "            im = rEYEker.draw_vertical_line_diagram(images[dataset_idx], stimulus_measurement, should_copy=True)\n",
    "            sequence_diagram_array.append(im)\n",
    "        except:\n",
    "            #TODO\n",
    "            print(\"W.I.P.:\", end='')\n",
    "            print(\"to many clicks for dataset \" + str(dataset_idx) + \" datset \" + str(visual_idx))\n",
    "    sequence_diagrams_datasets_array.append(sequence_diagram_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sequence_diagram_array in enumerate(sequence_diagrams_datasets_array):\n",
    "    save_images(sequence_diagram_array, \"./results/sequence_diagrams/\"  +  folder_prefix[idx], image_prefix[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5. Generate Code Flow diagramm</h2>\n",
    "\n",
    "<h4> User rEYEke_COdeFlow.ipynb to create the corresponding excel sheets </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>7. Analyse average of Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.1 Helper Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_displots(folder, indexing_array, dataframes):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    indexing_array: how to index into the dataframe\n",
    "    dataframes:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for idx, dataframe in enumerate(dataframes):\n",
    "        values = dataframe[indexing_array[idx]].values.astype(float)\n",
    "        sns_plot = sns.displot(data=values, kde=True)\n",
    "        sns_plot.savefig(folder + image_prefix[idx] + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "def save_combined_displot(folder, x_axis, dataframe):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    x_axis:         value to use for x_axis\n",
    "    dataframe:      dataframe with \"Algorithm\" field\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.displot(data=dataframe, x=x_axis, hue=\"Algorithm\", kind=\"kde\")\n",
    "    sns_plot.savefig(folder + \"Combined_Displot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_barplot(folder, y_axis, dataframes):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    dataframes:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.barplot(y=y_axis, x='Algorithm', data=dataframes, hue='Algorithm', estimator=np.median)\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Barplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxplot(folder, y_axis, dataframes):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    dataframes:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.boxplot(y=y_axis, x='Algorithm', data=dataframes, hue='Algorithm')\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Boxplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_violinplot(folder, y_axis, dataframes):\n",
    "    \"\"\"\n",
    "    folder:         prefix where to save\n",
    "    y_axis:         value to use for y_axis\n",
    "    dataframes:     array of dataframes to plot\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sns_plot = sns.violinplot(y=y_axis, x='Algorithm', data=dataframes, hue='Algorithm')\n",
    "    sns_plot.legend_.remove()\n",
    "    sns_plot.figure.savefig(folder + \"Combined_Violinplot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_implots(folder, x_df, x_axis, y_df, y_axis):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tmp_list = []\n",
    "    for idx in range(len(x_df)):\n",
    "        x_val = x_df[x_axis][idx]\n",
    "        y_val = y_df[y_axis][idx]\n",
    "        algorithm = x_df['Algorithm'][idx]\n",
    "        tmp_list.append([x_val, y_val, algorithm])\n",
    "        \n",
    "    df_tmp = pd.DataFrame(tmp_list, columns=[x_axis, y_axis, 'Algorithm'])\n",
    "    for idx in range(len(algo_names)):\n",
    "        tmp_df = df_tmp[df_tmp[\"Algorithm\"] == algo_names[idx]]\n",
    "        sns_plot = sns.lmplot(data=tmp_df, x=x_axis, y=y_axis)\n",
    "        sns_plot.set(ylim=(0, None))\n",
    "        sns_plot.savefig(folder + algo_names[idx] + str(idx) + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_combined_implot(folder, x_df, x_axis, y_df, y_axis):\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tmp_list = []\n",
    "    for idx in range(len(x_df)):\n",
    "        x_val = x_df[x_axis][idx]\n",
    "        y_val = y_df[y_axis][idx]\n",
    "        algorithm = x_df['Algorithm'][idx]\n",
    "        tmp_list.append([x_val, y_val, algorithm])\n",
    "        \n",
    "    df_tmp = pd.DataFrame(tmp_list, columns=[x_axis, y_axis, 'Algorithm'])\n",
    "    sns_plot = sns.lmplot(data=df_tmp, x=x_axis, y=y_axis, hue=\"Algorithm\")\n",
    "    sns_plot.set(ylim=(0, None))\n",
    "    sns_plot.savefig(folder + \"Combined_Implot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.2 Response Time</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new Dataframe which holds all the response time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Response Time', 'Algorithm']\n",
    "data = []\n",
    "for idx, dataframe in enumerate(dataframes):\n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data.append([row[response_time_data[idx]], algo_names[idx]])\n",
    "algo_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Save Displots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_displots(\"./results/responseTime/displots/\", response_time_data, dataframes)\n",
    "\n",
    "save_combined_displot(\"./results/responseTime/displots/\", \"Response Time\", algo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add joinplots when the outlier calculation is b4 the coordinates calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_barplot(\"./results/responseTime/barplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boxplot(\"./results/responseTime/boxplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_violinplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-7d07dd3303eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_violinplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./results/responseTime/violinplot/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Response Time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_violinplot' is not defined"
     ]
    }
   ],
   "source": [
    "save_violinplot(\"./results/responseTime/violinplot/\", 'Response Time', algo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.3. Code Flow vs Visual Stimulus</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load daraframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "config_array = []\n",
    "code_flow_array = []\n",
    "\n",
    "for value in code_flow_data:\n",
    "    sheet_config = pd.read_excel('./data/code_flow/' + value, sheet_name=\"config\")\n",
    "    sheet_config = sheet_config.astype('int32')\n",
    "    \n",
    "    sheet_code_flow = pd.read_excel('./data/code_flow/' + value, sheet_name=\"values\")\n",
    "    sheet_code_flow = sheet_code_flow.astype('int32')\n",
    "    \n",
    "    config_array.append(sheet_config)\n",
    "    code_flow_array.append(sheet_code_flow)\n",
    "\n",
    "# transform stimulus data into code lines\n",
    "visual_stimulus_code_flow_arrays = []\n",
    "\n",
    "for idx1, visual_stimulus_dataset in enumerate(visual_stimulus_data_array):\n",
    "    converted_to_lines_array = []\n",
    "    \n",
    "    for dataset in visual_stimulus_dataset:\n",
    "        converted_to_lines = []\n",
    "        \n",
    "        for (x, y) in dataset:\n",
    "            num = -1\n",
    "            \n",
    "            for idx2, tup in config_array[idx1].iterrows():\n",
    "                if is_in(y, tup):\n",
    "                    num = idx2\n",
    "            \n",
    "            converted_to_lines.append(num)\n",
    "            \n",
    "        converted_to_lines_array.append(converted_to_lines)\n",
    "        \n",
    "    visual_stimulus_code_flow_arrays.append(converted_to_lines_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sequence for visual stimulus flow\n",
    "        \n",
    "visual_stimulus_code_flow_sequence = []\n",
    "\n",
    "for idx, visual_stimulus_code_flow_datasets in enumerate(visual_stimulus_code_flow_arrays):\n",
    "    sequence_array = []\n",
    "    multiplier_offset = 10**get_0_offset(len(config_array[idx]))\n",
    "    \n",
    "    for visual_stimulus_code_flow_dataset in visual_stimulus_code_flow_datasets:\n",
    "        sequence = []\n",
    "        \n",
    "        for start in range(len(visual_stimulus_code_flow_dataset)-1):\n",
    "            pre = visual_stimulus_code_flow_dataset[start]\n",
    "            post = visual_stimulus_code_flow_dataset[start+1]\n",
    "            #potential skip if pre and post is equal, may be useful\n",
    "            num = pre * multiplier_offset + post\n",
    "            sequence.append(num)\n",
    "            \n",
    "        sequence_array.append(sequence)\n",
    "        \n",
    "    visual_stimulus_code_flow_sequence.append(sequence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen sequence for code flow\n",
    "code_flow_sequence_array = [] \n",
    "\n",
    "for code_flow_dataset in code_flow_array:\n",
    "    sequence = []\n",
    "    multiplier_offset = 10**get_0_offset(len(code_flow_dataset))\n",
    "    \n",
    "    for start in range(len(code_flow_dataset)-1):\n",
    "        pre = code_flow_dataset['code flow'][start]\n",
    "        post = code_flow_dataset['code flow'][start+1]\n",
    "        #potential skip if pre and post is equal, may be useful\n",
    "        num = pre * multiplier_offset + post\n",
    "        sequence.append(num)\n",
    "        \n",
    "    code_flow_sequence_array.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes\n",
    "similarity_array = []\n",
    "\n",
    "for idx, code_flow_sequence in enumerate(code_flow_sequence_array):\n",
    "    sim_data = []\n",
    "    for visual_stimulus_sequence in visual_stimulus_code_flow_sequence[idx]:\n",
    "        sim_data.append(difflib.SequenceMatcher(None, code_flow_sequence, visual_stimulus_sequence).ratio())\n",
    "        \n",
    "    similarity_array.append(sim_data)\n",
    "    \n",
    "cols = ['Similarity', 'Algorithm']\n",
    "data = []\n",
    "for idx in range(len(similarity_array)):\n",
    "    for score in similarity_array[idx]:\n",
    "        data.append([score, algo_names[idx]])\n",
    "\n",
    "df_similarity = pd.DataFrame(data, columns=cols)\n",
    "df_similarity_array = []\n",
    "for idx in range(len(code_flow_sequence_array)):\n",
    "    df = pd.DataFrame(df_similarity.loc[df_similarity['Algorithm'] == algo_names[idx]] ,columns=cols)\n",
    "    df = df.drop('Algorithm', axis=1)\n",
    "    df_similarity_array.append(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_displots(\"./results/codeFlowSimilarity/displots/\", [\"Similarity\"]*len(similarity_array), df_similarity_array)\n",
    "\n",
    "save_combined_displot(\"./results/displots/\", \"Similarity\", df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_barplot(\"./results/codeFlowSimilarity/barplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boxplot(\"./results/codeFlowSimilarity/boxplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_violinplot(\"./results/codeFlowSimilarity/violinplot/\", 'Similarity', df_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.4. Regression Code Flow and Response time</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_implots(\"./results/codeFlowSimilarity/implots/\", df_similarity, \"Similarity\", algo_df, \"Response Time\")\n",
    "save_combined_implot(\"./results/codeFlowSimilarity/implots/\", df_similarity, \"Similarity\", algo_df, \"Response Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7.5. Statistical Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Excel sheet with data containing speedup and significance corresponding to response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statical_data(df_array, indexing_array, folder, name):\n",
    "    def highlight_signficant(s):\n",
    "        if s.name != '#':\n",
    "            is_sig = df_significance[s.name]\n",
    "            return ['background-color: green' if v else '' for v in is_sig]\n",
    "        else:\n",
    "            return ['' for v in s] \n",
    "    \n",
    "    mean_array = []\n",
    "    is_significant = []\n",
    "    t_value_response_time = []\n",
    "    p_value_response_time = []\n",
    "    ratio = []\n",
    "\n",
    "    for idx1, df1 in enumerate(df_array):\n",
    "        different_tmp = [algo_names[idx1]]\n",
    "        t_tmp = [algo_names[idx1]]\n",
    "        p_tmp = [algo_names[idx1]]\n",
    "        ratio_tmp = [algo_names[idx1]]\n",
    "    \n",
    "        for idx2, df2 in enumerate(df_array):\n",
    "            (different, t, p) = compare_for_h0(df1[indexing_array[idx1]].values, df2[indexing_array[idx2]],  alpha)\n",
    "            different_tmp.append(not different)\n",
    "            t_tmp.append(t)\n",
    "            p_tmp.append(p)\n",
    "            ratio_tmp.append(df1[indexing_array[idx1]].mean() / df2[indexing_array[idx2]].mean())\n",
    "        \n",
    "        is_significant.append(different_tmp)\n",
    "        t_value_response_time.append(t_tmp)\n",
    "        p_value_response_time.append(p_tmp)\n",
    "        ratio.append(ratio_tmp)\n",
    "        mean_array.append(df1[indexing_array[idx1]].mean())\n",
    "    \n",
    "    df_significance = pd.DataFrame(is_significant, columns=['#'] + algo_names)\n",
    "\n",
    "    df_t = pd.DataFrame(t_value_response_time, columns=['#'] + algo_names)\n",
    "    df_p = pd.DataFrame(p_value_response_time, columns=['#'] + algo_names)\n",
    "    df_ratio = pd.DataFrame(ratio, columns=['#'] + algo_names)\n",
    "    df_ratio = df_ratio.style.apply(highlight_signficant)\n",
    "    df_mean = pd.DataFrame([mean_array], columns=algo_names)\n",
    "\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    writer = pd.ExcelWriter(folder + name + '.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    df_ratio.to_excel(writer, sheet_name='ratio col row', index=False)\n",
    "    df_mean.to_excel(writer, sheet_name='mean value', index=False)\n",
    "    df_significance.to_excel(writer, sheet_name='statistical difference', index=False)\n",
    "    df_p.to_excel(writer, sheet_name='p values', index=False)\n",
    "    df_t.to_excel(writer, sheet_name='t values', index=False)\n",
    "\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Excel sheet with data containing speedup and significance corresponding to len of measured visual stimulus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statical_data(dataframes, response_time_data, './results/excel/', 'TotalResponseTime')\n",
    "create_statical_data(len_dataframes, ['len']*len(len_dataframes), './results/excel/', 'NumberOfMeasurements')\n",
    "create_statical_data(df_similarity_array, ['Similarity']*len(df_similarity_array), './results/excel/', 'SimilarityToCodeFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>8. Areas of Interest </h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
